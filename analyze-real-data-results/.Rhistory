)
# ── 1. Read and prepare ONS data ─────────────────────────────────────────
ons <- read.table("../data/ons_survey_data.tsv")
ons$prop <- ons$V4 / 100
ons$date <- as.Date(
paste(ons$V3, ons$V2, ons$V1, sep = "-"),   # "2023-March-1"
format = "%Y-%B-%d"
)
# ── 2. Build the original plot (your code) ──────────────────────────────
summary_df$prop <- summary_df$n_inferred / summary_df$n_samples
p_prop <- ggplot(summary_df, aes(date, prop)) +
geom_ribbon(
aes(ymin = ci_prop_lo, ymax = ci_prop_hi, colour = NULL),  # no colour mapping
fill  = "lightblue", alpha = 0.3, show.legend = FALSE
) +
geom_line(aes(colour = "Detected"), linewidth = 0.4) +
geom_line(aes(colour = "95% CI"),    linewidth = 0.4, alpha = 0) +
## ── 3.  ONS line with its own colour mapping  ──
geom_line(
data   = ons,
aes(x = date, y = prop, colour = "ONS prevalence"),
linewidth = 0.4
) +
## single discrete colour scale for all three keys
scale_colour_manual(
breaks = c("Detected", "95% CI", "ONS prevalence"),
values = c("Detected"       = "black",
"95% CI"         = "lightblue",
"ONS prevalence" = "red"),
name   = NULL,
guide  = guide_legend(
override.aes = list(
linetype = rep("solid", 3),
size     = rep(0.4,    3),
alpha    = rep(1,      3)
)
)
) +
scale_y_continuous(
labels  = percent_format(accuracy = 0.1),
limits  = c(0, 0.10)
) +
labs(
x = "Date",
y = "Proportion detected as recombinant"
) +
theme_bw() +
theme(
legend.position      = c(0.98, 0.98),
legend.justification = c(1, 1),
legend.background    = element_rect(fill = "white", colour = NA)
)
# ── 4. Save figure ──────────────────────────────────────────────────────
ggsave(
"figs/recombinant_prop_time_series_with_ONS.png",
plot   = p_prop,
width  = 10, height = 4, dpi = 300, units = "in"
)
# ── 3. Build the plot with larger fonts ────────────────────────────────
base_font <- 27           # try 18–22 for slides
p_prop <- ggplot(summary_df, aes(date, prop)) +
geom_ribbon(
aes(ymin = ci_prop_lo, ymax = ci_prop_hi),
fill = "lightblue", alpha = 0.3, show.legend = FALSE
) +
geom_line(aes(colour = "Detected"),    linewidth = 0.4) +
geom_line(aes(colour = "95% CI"),      linewidth = 0.4, alpha = 0) +
geom_line(
data = ons,
aes(date, prop, colour = "ONS prevalence"),
linewidth = 0.4
) +
scale_colour_manual(
breaks = c("Detected", "95% CI", "ONS prevalence"),
values = c(
"Detected"       = "black",
"95% CI"         = "lightblue",
"ONS prevalence" = "red"
),
# Optional pretty labels:
labels = c(
"Detected"       = "Proportion detected as recombinant",
"95% CI"         = "95% CI",
"ONS prevalence" = "Population prevalence of SARS-CoV-2"
),
name = NULL,
guide = guide_legend(
override.aes = list(linetype = "solid", size = 0.4, alpha = 1))
) +
scale_y_continuous(
labels = percent_format(accuracy = 0.1),
limits = c(0, 0.10)
) +
labs(
x = "Date",
y = "Proportion"
) +
theme_bw(base_size = base_font) +       # ← master font knob
theme(
legend.position      = c(0.98, 0.98),
legend.justification = c(1, 1),
legend.background    = element_rect(fill = "white", colour = NA)
)
p_prop
ggsave(
"figs/recombinant_prop_time_series_with_ONS.png",
plot   = p_prop,
width  = 12, height = 6, dpi = 300, units = "in"
)
library(tidyverse)
library(lubridate)
library(ggrepel)
library(viridis)
library(readr)
library(patchwork)
### load data
gene_ann <- read_tsv(
"../data/gene_annotation.gff",
comment = "#",
col_names = FALSE,
show_col_types = FALSE
)
colnames(gene_ann) <- c(
"seqid","source","feature","start",
"end","score","strand","phase","attributes"
)
# Define genes to label in overall track
focal_genes <- c("ORF1ab", "S", "N")
# Extract all gene features
gene_bounds <- gene_ann %>%
filter(feature == "gene") %>%
mutate(
gene = str_extract(attributes, "(?<=Name=)[^;]+"),
gene = if_else(is.na(gene),
str_extract(attributes, "(?<=ID=)[^;]+"),
gene),
mid = (start + end) / 2
) %>%
select(start, end, mid, gene)
res <- read.csv("summary_files/combined_optimization_results_with_summary.csv")
dist_break <- res %>% group_by(n_breakpoints) %>% summarize(n = n())
sum(dist_break$n[-1]*dist_break$n_breakpoints[-1])
dist_break <- dist_break[-1,]
dist_break$n/sum(dist_break$n)
8/sum(dist_break$n)
library(tidyverse)
library(stringr)
library(readr)
library(purrr)
library(data.table)
# Inferred
res <- read.csv("summary_files/combined_optimization_results_with_summary.csv") %>%
mutate(across(c(test_start, test_end), as.Date)) %>%
mutate(date = test_start + (test_end - test_start) / 2)
# add number of parental lineages
res_w_n_parents <- res %>%
mutate(
n_parents = case_when(
is.na(parental_lineages) | parental_lineages == "" ~ 0L,
TRUE ~ str_count(parental_lineages, fixed(";")) + 1L
)
)
# counts
n_three_or_more <- sum(res_w_n_parents$n_parents >= 3, na.rm = TRUE)
n_one_only      <- sum(res_w_n_parents$n_parents == 1, na.rm = TRUE)
# filtered data: keep exactly 2 parental lineages
res_filtered <- res_w_n_parents %>%
filter(n_parents == 2) %>%
select(-n_parents)
# (optional) quick sanity table
tally_parents <- res_w_n_parents %>%
count(n_parents, name = "n_rows") %>%
arrange(n_parents)
# Compute numerator and denominator
num <- nrow(res_filtered)
den <- sum(tally_parents$n_rows[-1])
# Exact (Clopper–Pearson) binomial CI
bt <- binom.test(num, den)
bt$estimate   # estimated proportion
bt$conf.int   # exact 95% Clopper–Pearson CI
# split parents (for those with two parental lineages)
tmp <- res_filtered %>%
separate(parental_lineages, into = c("pA", "pB"), sep = ";", remove = FALSE)
# how many rows have "other" as a parent
n_with_other <- tmp %>%
filter(str_to_lower(pA) == "other" | str_to_lower(pB) == "other") %>%
nrow()
# drop rows with "other", canonicalize ordering, and tally
pair_counts <- tmp %>%
filter(str_to_lower(pA) != "other", str_to_lower(pB) != "other") %>%
mutate(parent1 = pmin(pA, pB), parent2 = pmax(pA, pB)) %>%
count(parent1, parent2, name = "n_sequences") %>%
arrange(desc(n_sequences), parent1, parent2)
# pair_counts has the number of detected recombinants with each unique parental lineage pair
# drop rows with "other", canonicalize ordering, and tally
pair_counts_w_other <- tmp %>%
mutate(parent1 = pmin(pA, pB), parent2 = pmax(pA, pB)) %>%
count(parent1, parent2, test_start, name = "n_sequences") %>%
arrange(test_start, parent1, parent2)
### Above, we already obtained the observed counts, so from here, we calculate expected counts
# Get number of samples and number of detected recombinants with two parental lineages in each window
res_pairs <- res %>%
add_count(date, name = "n_samples") %>%          # <- adds n_samples per date
filter(str_count(parental_lineages, ";") == 1) %>%
group_by(date, test_start, test_end, n_samples) %>%
summarise(n_inferred = n(), .groups = "drop")
sum(res_pairs$n_inferred)
# Get test windows
windows <- res_pairs %>% select(test_start, test_end)
# Read and prepare ONS data
ons <- read.table("../data/ons_survey_data.tsv")
ons <- ons %>%
transmute(
day   = V1, month_name = V2, year = V3, percent = V4,
prop  = percent / 100,
date  = as.Date(paste(year, month_name, day, sep = "-"), format = "%Y-%B-%d")
)
# Expand windows to daily dates, join, and summarize
# The first four lines are left joining ons prevalence to expanded windows (now we have window and day as each row)
ans2 <- windows %>%
mutate(date = map2(test_start, test_end, ~ seq(.x, .y, by = "day"))) %>%
unnest(date) %>%
left_join(ons, by = "date") %>%
group_by(test_start, test_end) %>%
summarise(
avg_prop = mean(prop, na.rm = TRUE),
n_days   = sum(!is.na(prop)),
.groups  = "drop")
### Above, we obtained window-averaged ONS estimates. Next, we need lineage proportions.
# folder containing the files (adjust as needed)
dir_in <- "../run-on-cluster-3/real-data-analysis/output/sliding_windows/expected_recombinant_freq"
# regex for filenames like: lineage_freq_2024-02-19_2024-02-25.csv.gz
pat <- "^lineage_freq_(\\d{4}-\\d{2}-\\d{2})_(\\d{4}-\\d{2}-\\d{2})\\.csv\\.gz$"
file_df <- tibble(
path = list.files(dir_in, pattern = pat, full.names = TRUE)) %>%
mutate(
fname      = basename(path),
test_start = as.Date(str_match(fname, pat)[, 2]),
test_end   = as.Date(str_match(fname, pat)[, 3]))
# (optional) sanity check
stopifnot(all(!is.na(file_df$test_start)), all(!is.na(file_df$test_end)))
lineage_freq_all <- file_df %>%
select(path, test_start, test_end) %>%
pmap_dfr(function(path, test_start, test_end) {
read_csv(path, show_col_types = FALSE) %>%
mutate(test_start = test_start,
test_end   = test_end)})
# Result: one big data frame with the original columns + test_start/test_end
lineage_freq_all
# Here, we are obtaining sum (pipj) across all i<j, which is what we need to fit the linear regression later
pair_mass <- lineage_freq_all %>%
group_by(test_start, test_end) %>%
summarise(
s1 = sum(p, na.rm = TRUE),
s2 = sum(p^2, na.rm = TRUE),
sum_pipj = 0.5 * (s1^2 - s2),
.groups = "drop"
)
# Sanity check
pair_mass2 <- lineage_freq_all %>%
group_by(test_start, test_end) %>%
summarise(
sum_pipj = {
v <- p[!is.na(p)]
if (length(v) < 2) 0 else sum(combn(v, 2, FUN = prod))
},
.groups = "drop"
)
pair_mass
pair_mass2
# test
# pairs_coexist <- lineage_freq_all %>%
#   group_by(test_start) %>%
#   summarise(lineages = list(unique(collapsed)), .groups = "drop")
#
# lapply(pairs_coexist$lineages, function(x){"AY.9" %in% x & "B.1.617.2" %in% x})
# Using lineage proportions + ONS prev estimates, we next estimate theta and phi using a linear regression.
# To the inferred number of recombinant sequences in each window, left join sum pipj in each window and the window-averaged ons prev.
window_stats <- res_pairs %>% left_join(pair_mass) %>% left_join(ans2)
# window_stats$denom <- window_stats$n_samples*window_stats$avg_prop*window_stats$sum_pipj
# window_stats$theta_first_model <- window_stats$n_inferred/window_stats$denom
# x_w = prev(w) sum pi(w)pj(w)
window_stats$x <- window_stats$avg_prop*window_stats$sum_pipj
# y_w = R^{total}(w)/n(w)
window_stats$y <- window_stats$n_inferred/window_stats$n_samples
window_stats <- window_stats[!is.na(window_stats$x),]
ggplot(window_stats, aes(x, y)) + geom_point()
# linear regression to est. theta and phi
lm <- lm(y~x, data = window_stats)
summary_lm <- summary(lm)
vc <- vcov(lm)
# Point estimates
phi_hat   <- summary_lm$coefficients[1, 1]
beta_hat  <- summary_lm$coefficients[2, 1]
theta_hat <- phi_hat + beta_hat
# Standard errors
se_phi   <- sqrt(vc[1, 1])
se_theta <- sqrt(vc[1, 1] + vc[2, 2] + 2 * vc[1, 2])
# Critical value (e.g., 95% CI)
alpha <- 0.05
z_crit <- qnorm(1 - alpha / 2)
# Wald CIs
phi_CI   <- c(phi_hat - z_crit * se_phi,   phi_hat + z_crit * se_phi)
theta_CI <- c(theta_hat - z_crit * se_theta, theta_hat + z_crit * se_theta)
phi_hat
phi_CI
theta_hat
theta_CI
### Finally, we are ready to estimate recombinant counts
lineage_freq_all
# Get pipj for all i<j and all windows (using self-join with window id)
pairs_by_window <- lineage_freq_all %>%
filter(test_end <= as.Date("2023-03-19")) %>%
transmute(test_start, test_end, lineage = collapsed, p) %>%
group_by(test_start, test_end) %>%
mutate(.row = row_number()) %>%
ungroup() %>%                                         # <-- important: ungroup before self-join
inner_join(., ., by = c("test_start", "test_end"),
suffix = c("_i", "_j")) %>%
filter(.row_i < .row_j) %>%
transmute(
test_start, test_end,
i_raw  = lineage_i, j_raw  = lineage_j,
pi_raw = p_i,       pj_raw = p_j
) %>%
mutate(
i  = pmin(i_raw, j_raw),
j  = pmax(i_raw, j_raw),
pi = if_else(i_raw == i,  pi_raw, pj_raw),  # swap p’s if we swapped labels
pj = if_else(i_raw == i,  pj_raw, pi_raw),
pipj = pi * pj
) %>%
select(test_start, test_end, i, j, pi, pj, pipj)
# Attach theta, prev, and n
calculate_exp <- pairs_by_window %>% left_join(window_stats %>% select(test_start, test_end, n_samples, avg_prop))
calculate_exp$theta_hat <- theta_hat
# \hat E[R] = theta*n*prev*pi*pj (in each window)
calculate_exp$exp_hat <- calculate_exp$theta_hat * calculate_exp$n_samples * calculate_exp$avg_prop * calculate_exp$pipj
# sum across windows
calculate_exp_agg <- calculate_exp %>% group_by(i,j) %>% summarize(exp_hat = sum(exp_hat)) %>% arrange(desc(exp_hat))
colnames(calculate_exp_agg) <- c("parent1", "parent2", "exp")
### We have both obs. and exp. counts! Now join the two!
# How many sequences tested during ONS period?
res %>% filter(test_end <= as.Date("2023-03-19")) %>% nrow()
# Prep: normalize parents and apply date filter once
# temp has only two parental lineages
prep <- tmp %>%
mutate(
parent1 = pmin(pA, pB),
parent2 = pmax(pA, pB)
) %>%
filter(test_end <= as.Date("2023-03-19"))
# (1) Pair counts excluding 'other' (your original goal)
pair_counts_during_ons <- prep %>%
filter(parent1 != "other", parent2 != "other") %>%
count(parent1, parent2, name = "n_sequences") %>%
arrange(desc(n_sequences), parent1, parent2)
# (2) How many rows (within the date filter) have at least one 'other'
other_counts <- prep %>%
summarise(
n_total_in_range   = n(),
n_with_other       = sum(parent1 == "other" | parent2 == "other", na.rm = TRUE),
n_without_other    = sum(parent1 != "other" & parent2 != "other", na.rm = TRUE)
)
other_counts
sum(pair_counts_during_ons$n_sequences)
pair_counts_w_exp <- left_join(pair_counts_during_ons, calculate_exp_agg)
sum(pair_counts_w_exp$n_sequences)-sum(pair_counts_w_exp$exp)
library(dplyr)
library(ggplot2)
library(scales)
library(ggrepel)
#--- Data + model --------------------------------------------------------------
# Assumes pair_counts_w_exp has columns: n_sequences (x), exp (y),
# and parental pair identifiers parent1, parent2
# Fit OLS and get residuals
fit <- lm(n_sequences ~ exp, data = pair_counts_w_exp)
summary(fit)
df_with_res <- pair_counts_w_exp %>%
mutate(
.resid    = resid(fit),
.stdresid = rstandard(fit),
label     = paste0(parent1, " - ", parent2)
)
# Which points to label? (|standardized residual| >= 3)
pairs_to_label <- df_with_res %>%
arrange(desc(abs(.resid))) %>%   # sort by extremeness
slice_head(n = 20)
#--- Correlation test (Pearson, complete cases) --------------------------------
ct <- with(pair_counts_w_exp,
cor.test(n_sequences, exp, use = "complete.obs", method = "pearson"))
r_val <- unname(ct$estimate)
p_val <- ct$p.value
n_obs <- sum(complete.cases(pair_counts_w_exp[, c("n_sequences", "exp")]))
cap_text <- sprintf("Pearson correlation r = %.3f (p = %.3g), n = %d", r_val, p_val, n_obs)
#--- Plot ----------------------------------------------------------------------
p_pairs <- ggplot(pair_counts_w_exp, aes(x = exp, y = n_sequences)) +
geom_point(alpha = 0.7, size = 1.9, stroke = 0) +
geom_abline(slope = 1) +
# Least-squares line with 95% CI ribbon
geom_smooth(method = "lm", se = TRUE, linewidth = 0.8) +
scale_x_continuous(labels = label_number(accuracy = 1), expand = expansion(mult = c(0.02, 0.05))) +
scale_y_continuous(labels = label_number(accuracy = 1), expand = expansion(mult = c(0.02, 0.05))) +
labs(
y = "Detected recombinants",
x = "Expected true positive recombinants",
caption = cap_text
) +
theme_bw(base_size = 15) +
theme(
legend.position = "none",
plot.caption = element_text(hjust = 0)
)
# Add labels for large standardized residuals (if any)
p_pairs_lab <- p_pairs +
geom_text_repel(
data = pairs_to_label,
aes(label = label),
size = 3.2,
max.overlaps = Inf,
box.padding = 0.25,
point.padding = 0.2,
min.segment.length = 0,
seed = 42
)
# Draw & save
p_pairs_lab
ggsave("figs/pairs_scatter_detected_vs_expected.png",
p_pairs_lab, width = 6, height = 6, dpi = 300)
# Which points to label? (|standardized residual| >= 3)
label2 <- df_with_res %>%
arrange(desc(abs(.resid))) %>%   # sort by extremeness
slice_head(n = 20) %>% filter(.stdresid < 0)
library(scales)
# --- define pairs of interest ---
pairs_tbl <- tibble::tibble(
i = c("BA.1","BA.1","BA.1.1","BQ.1.1","BA.1.1","CH.1.1"),
j = c("BA.1.1","BA.1.17.2","BA.1.17.2","CH.1.1","BA.2","XBB.1.5")
)
pairs_keys <- pairs_tbl %>%
mutate(key = paste(pmin(i, j), pmax(i, j), sep = "-")) %>%
distinct(key) %>%
pull(key)
# --- normalize pairs in your data and filter ---
use_plot <- calculate_exp %>%
mutate(
key  = paste(pmin(i, j), pmax(i, j), sep = "-"),
pair = key,
mid_date = test_start + (test_end - test_start) / 2  # midpoint of window
) %>%
filter(key %in% pairs_keys)
# --- Plot trajectories of expected counts over time -------------
p_expected <- ggplot(use_plot, aes(x = mid_date, y = pipj, color = pair)) +
geom_line(linewidth = 0.8, alpha = 0.9) +
geom_point(size = 1.9, alpha = 0.8, stroke = 0) +
scale_x_date(
date_breaks = "2 months",
date_labels = "%b %Y",
expand = expansion(mult = c(0.02, 0.05))
) +
scale_y_continuous(
labels = scales::label_scientific(digits = 2),
expand = expansion(mult = c(0.02, 0.05))
) +
labs(
x = "Date",
y = expression(Joint~lineage~frequencies~(p[i]~p[j])),
color = "Parental lineage pair"
) +
theme_bw(base_size = 15) +
theme(
plot.caption = element_text(hjust = 0),
legend.position = "right",
axis.text.x = element_text(angle = 45, hjust = 1)
)
p_expected
ggsave("figs/pipj_selected_pairs.png",
p_expected, width = 8, height = 4, dpi = 300)
pair_counts_during_ons_other <- prep %>%
count(parent1, parent2, name = "n_sequences") %>%
arrange(desc(n_sequences), parent1, parent2)
View(pair_counts_during_ons)
View(pair_counts_during_ons_other)
View(lineage_freq_all)
# test
lineage_freq_all_other <- lineage_freq_all %>% filter(collapsed == "other")
ggplot(lineage_freq_all_other, aes(x = test_start, y = p)) + geom_line()
library(tidyverse)
library(scales)
library(data.table)
# ── Inferred recombinants ─────────────────────────────────────────────────────
res <- read.csv("summary_files/combined_optimization_results_with_summary.csv") %>%
mutate(across(c(test_start, test_end), as.Date)) %>%
mutate(date       = test_start + (test_end - test_start) / 2)
res_pairs <- res %>%
add_count(date, name = "n_samples") %>%          # <- adds n_samples per date
filter(str_count(parental_lineages, ";") >= 1) %>%
group_by(date, test_start, test_end, n_samples) %>%                    # keep n_samples in the key
summarise(n_inferred = n(), .groups = "drop")
# Exact binomial CIs ⇒ *count* scale
ci_exact <- function(k, n) binom.test(k, n)$conf.int
summary_df <- res_pairs %>%
mutate(
ci_lo       = map2_dbl(n_inferred, n_samples, ~ ci_exact(.x, .y)[1] * .y),
ci_hi       = map2_dbl(n_inferred, n_samples, ~ ci_exact(.x, .y)[2] * .y),
ci_prop_lo  = map2_dbl(n_inferred, n_samples, ~ ci_exact(.x, .y)[1]),
ci_prop_hi  = map2_dbl(n_inferred, n_samples, ~ ci_exact(.x, .y)[2])
)
summary_df$prop <- summary_df$n_inferred/summary_df$n_samples
windows <- summary_df %>% select(test_start, test_end)
View(windows)
View(summary_df)
